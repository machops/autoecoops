# Contracts-L1 架構演進完整指南

## 引言

本文檔提供 Contracts-L1 從智能單體架構演進到完全微服務架構的詳細指南。無論您的團隊處於哪個發展階段,都能找到對應的最佳實踐與具體行動步驟。架構演進不是一蹴而就的重構,而是伴隨業務成長的漸進式優化過程。

## 演進決策框架

### 何時保持單體架構

在以下情況下,智能單體架構是最佳選擇,不應貿然拆分為微服務。團隊規模小於十人時,微服務的通訊協調成本會超過其帶來的好處,單體架構的簡單性讓小團隊能夠快速迭代。月活躍使用者少於一萬人時,單體應用配合垂直擴展足以應對負載,無需水平擴展多個服務。產品方向尚不明確時,頻繁的業務邏輯變更在單體架構中更容易實施,跨服務的重構成本過高。技術債務嚴重時,應優先清理現有代碼而非引入分散式系統的額外複雜性。

### 何時開始混合架構

當出現以下信號時,應考慮將特定模組拆分為獨立服務。某個模組成為明顯的性能瓶頸,例如 AI 分析任務阻塞其他請求,拆分後可以獨立擴展運算資源。團隊開始按功能領域劃分,不同小組負責不同模組時,服務邊界與團隊邊界對齊能提高自主性與交付速度。部署週期拉長,因為即使微小變更也需要部署整個應用,獨立服務可以更頻繁地部署而不影響其他部分。技術異構需求出現,例如某個模組更適合用 Python 而非 Node.js 實作,或需要特殊的硬體配置如 GPU。

### 何時演進到完全微服務

完全微服務架構適合已經成熟的大型系統,具備以下特徵。團隊規模超過二十人,分為多個自治小組,每個小組負責端到端的服務開發運維。使用者規模達到數十萬,單體架構即使垂直擴展也無法支撐負載,需要精細的水平擴展策略。業務領域複雜,涉及多個獨立的限界上下文,這些上下文在業務邏輯上本就應該隔離。技術成熟度高,團隊熟悉分散式系統的設計模式,具備處理最終一致性、服務發現、故障隔離等挑戰的能力。

## 階段一:智能單體架構優化

### 模組化設計原則

即使在單體架構階段,也應遵循高內聚低耦合的模組化原則。每個業務領域如使用者管理、契約處理、AI 分析、通知服務都應該是獨立的模組,擁有清晰的邊界與職責。模組之間的依賴關係應該是單向的,形成分層架構而非網狀依賴,這樣未來拆分時才能順利解耦。

實作層面使用資料夾結構明確劃分模組,每個模組包含自己的資料模型、業務邏輯、服務介面。跨模組呼叫必須透過公開的服務介面,禁止直接存取其他模組的內部實作細節。這種約束可以透過程式碼審查與靜態分析工具強制執行,例如使用 NX 的模組邊界規則。

### 資料庫隔離策略

雖然使用單一 PostgreSQL 實例,但透過 Schema 隔離不同業務領域的資料表。使用者相關表在 auth schema,契約資料在 contracts schema,分析結果在 analytics schema。這種邏輯隔離讓未來遷移到獨立資料庫變得可行,只需要將 Schema 匯出到新實例即可。

跨 Schema 的關聯應該最小化,優先透過服務層的業務邏輯關聯,而非資料庫外鍵。例如契約與使用者的關聯透過 user_id 欄位存儲,但不建立跨 Schema 的外鍵約束。這讓兩個 Schema 在資料庫層面完全獨立,遷移時不會有依賴問題。

### 事件驅動架構準備

在單體架構中引入事件總線機制,為未來的服務拆分做準備。當重要的業務事件發生時如契約上傳完成、分析結束、使用者註冊,發布事件到進程內的事件總線。其他模組訂閱感興趣的事件並執行相應邏輯,而非直接呼叫對方的方法。

實作事件總線可以使用簡單的 EventEmitter 模式,或引入 NestJS 的 CQRS 模組。關鍵是建立事件驅動的思維模式與程式碼結構,當未來拆分為微服務時,只需要將進程內事件總線替換為分散式消息佇列如 Redis Pub/Sub 或 RabbitMQ,業務邏輯無需大幅修改。

### 監控與可觀測性建設

從一開始就建立完善的監控體系,為架構演進提供數據支撐。使用 Prometheus 收集關鍵業務指標如每個模組的請求量、回應時間、錯誤率。使用結構化日誌記錄重要操作,包含請求追蹤 ID 以便關聯分散在不同模組的日誌。

定期檢視這些指標識別性能瓶頸與負載分佈。當發現某個模組的負載遠高於其他模組,且回應時間成為系統瓶頸時,就是考慮拆分的信號。當某個模組的錯誤率異常高,影響整個系統穩定性時,隔離成獨立服務可以限制故障範圍。

## 階段二:向混合架構演進

### 服務拆分優先順序

並非所有模組都應該同時拆分,應該根據收益與風險評估優先順序。第一優先是資源密集型服務,AI 分析引擎消耗大量 CPU 與記憶體,且執行時間長,獨立部署後可以使用高配置實例並獨立擴展,不會影響其他輕量級服務的回應速度。

第二優先是變更頻繁的服務,如果某個模組需要頻繁發布新版本實驗新算法或快速修復問題,獨立服務可以更快的部署週期而不必等待整個應用的回歸測試。第三優先是技術異構需求,例如圖像處理服務更適合用 Python 實作以利用豐富的科學計算庫,或某個服務需要 GPU 支援。

### 漸進式扼殺者模式

拆分服務時採用漸進式扼殺者模式而非大爆炸式重寫,降低風險並保持系統持續可用。首先在單體應用外部建立新的獨立服務,實作相同的功能但使用更適合的技術棧或架構。新舊服務並行運作一段時間,使用功能開關控制流量逐步從單體切換到新服務。

初期僅將百分之五的流量導向新服務,密切監控其穩定性與性能。如果一切正常,逐步提高比例到百分之二十、五十、百分之百。在整個過程中保留單體的對應功能作為回滾保險,確認新服務完全穩定後才移除單體中的代碼。

這種方式的優勢是風險可控,任何問題都可以立即回滾到單體。團隊可以在真實流量下驗證新服務的表現,積累分散式系統的運維經驗。使用者完全不會感知到背後的架構變化,避免服務中斷。

### API Gateway 引入

混合架構需要統一的 API 入口管理單體與微服務的路由。引入 API Gateway 作為所有外部請求的入口點,根據路徑規則將請求轉發到單體應用或特定的微服務。

API Gateway 除了路由功能,還承擔認證授權、速率限制、請求日誌、監控指標收集等橫切關注點。這些邏輯從各個服務中抽離到 Gateway 層,避免重複實作並確保一致性。Gateway 本身應該是無狀態的輕量級代理,避免成為性能瓶頸。

初期可以使用簡單的 Nginx 反向代理配合 Lua 腳本實現路由邏輯。隨著複雜度增加,可以升級到專門的 API Gateway 如 Kong 或雲端託管的 AWS API Gateway。重要的是從一開始就建立統一入口的架構模式,為未來更多服務的加入做準備。

### 服務間通訊設計

微服務之間需要明確的通訊機制,包括同步與異步兩種模式。同步通訊使用 REST API 或 gRPC,適合需要立即回應的查詢操作。異步通訊使用消息佇列如 Redis Streams 或 RabbitMQ,適合耗時的任務如發送郵件、生成報表、資料同步。

服務發現機制讓服務能夠動態找到彼此的位置。在雲端環境可以使用 DNS 服務發現,每個服務註冊一個固定的域名,Gateway 與其他服務透過域名呼叫而不是硬編碼 IP。本地開發環境可以使用 Docker Compose 的服務名稱解析。

為服務間通訊建立標準的錯誤處理與重試邏輯。網路呼叫可能失敗,服務可能暫時不可用,必須優雅處理這些情況。實作指數退避重試避免壓垮已經過載的服務,設定合理的超時時間防止級聯延遲,使用熔斷器模式在連續失敗時快速失敗而非持續等待。

### 資料一致性策略

微服務架構放棄了單體應用中事務的強一致性,轉向最終一致性模型。跨服務的業務操作不能使用資料庫事務保證原子性,必須透過其他機制協調。

Saga 模式是常用的分散式事務解決方案,將長事務拆分為多個本地事務,每個服務執行自己的事務並發布事件。如果某個步驟失敗,執行補償操作撤銷已完成的步驟。例如訂單服務創建訂單、支付服務扣款、庫存服務減庫存,如果扣款失敗則取消訂單並回復庫存。

事件溯源是另一種方案,不直接修改狀態而是記錄狀態變更事件,當前狀態由事件序列重建。這種方式天然支援審計追蹤,可以回溯到任意時間點的狀態,但增加了儲存與查詢的複雜度。在 Contracts-L1 中可以對關鍵業務如契約狀態變更應用事件溯源,保留完整的歷史軌跡。

## 階段三:完全微服務架構

### 服務粒度設計

微服務的粒度是架構設計的核心挑戰,過粗失去微服務的優勢,過細增加複雜性與通訊開銷。理想的服務應該對應一個限界上下文,擁有完整的業務能力而不依賴其他服務完成核心功能。

判斷服務粒度是否合適的標準包括團隊所有權,一個五到八人的小團隊能夠負責整個服務的開發測試部署運維。業務內聚性,服務內的功能因為相同的業務原因而變更,服務間的功能因為不同的業務原因而變更。變更頻率,服務內的功能變更頻率相近,避免將穩定功能與頻繁變更功能放在同一服務。

在 Contracts-L1 的完全微服務架構中,可能的服務劃分包括使用者認證服務負責註冊登入權限管理,契約上傳服務處理文件接收與儲存,文件解析服務提取 PDF Word 的文字內容,AI 條款識別服務調用語言模型識別條款,風險評估服務計算風險分數,向量索引服務管理語義向量,圖譜查詢服務執行知識圖譜查詢,通知服務發送各種通知,訂閱管理服務處理計費與配額,數據分析服務產生使用報表。

### 容器化與編排

每個微服務打包為 Docker 容器,確保環境一致性與可移植性。容器映像應該盡可能小,使用多階段構建分離編譯環境與執行環境,選擇精簡的基礎映像如 Alpine Linux,只包含必要的依賴。

Kubernetes 作為容器編排平台,提供服務發現、負載均衡、自動擴展、滾動更新、健康檢查等能力。每個微服務定義 Deployment 描述副本數量與更新策略,Service 暴露穩定的訪問端點,ConfigMap 與 Secret 管理配置與敏感資訊。

自動擴展根據 CPU 記憶體使用率或自定義指標如請求佇列長度動態調整副本數量。高峰期自動增加實例處理負載,低谷期縮減實例節省成本。設定合理的最小與最大副本數,避免過度擴展消耗資源或縮減不足無法應對突發流量。

### 服務網格

隨著服務數量增長,服務間通訊的複雜度呈指數級上升。服務網格如 Istio 或 Linkerd 提供統一的通訊層,處理服務發現、負載均衡、重試、熔斷、分散式追蹤等問題,讓應用代碼專注業務邏輯。

服務網格透過 Sidecar 模式運作,每個服務實例旁邊運行一個代理容器攔截所有進出流量。代理之間組成服務網格的資料平面,控制平面統一配置所有代理的行為。應用容器無需感知服務網格的存在,所有通訊策略在基礎設施層配置。

分散式追蹤能力讓請求在多個服務間的完整路徑可視化,快速定位性能瓶頸與錯誤來源。每個請求分配唯一追蹤 ID,經過的每個服務記錄 span 包含開始時間、結束時間、服務名稱、操作名稱,這些 span 關聯起來形成完整的追蹤樹。Jaeger 或 Zipkin 收集與展示追蹤數據,幫助理解系統行為。

### 資料管理策略

完全微服務架構中每個服務擁有獨立資料庫,實現資料自治。服務間不能直接存取彼此的資料庫,必須透過 API 呼叫獲取數據。這種隔離帶來運營複雜度如備份、遷移、一致性維護都需要獨立處理,但換來技術靈活性與故障隔離。

對於需要跨服務查詢的場景,建立專門的查詢服務或 CQRS 模式的讀模型。寫操作在各自的服務執行,發布領域事件,查詢服務訂閱這些事件更新自己的資料庫視圖。讀寫分離讓查詢可以使用不同的資料結構如反正規化表甚至不同的資料庫技術如 Elasticsearch 優化查詢性能。

事件溯源與 CQRS 結合使用效果最佳,事件流作為唯一真實來源,多個讀模型從事件流重建適合不同查詢需求的資料視圖。這種架構支援時間旅行查詢、審計追蹤、實時分析,但需要處理事件版本演進與讀模型重建的複雜性。

## 演進過程的風險管理

### 技術風險

分散式系統引入的複雜性是主要技術風險。網路不可靠導致服務間呼叫可能失敗,必須處理超時、重試、冪等性。時鐘漂移導致不同服務的時間不一致,影響排序與超時判斷。部分失敗狀態下系統處於不一致狀態,需要最終一致性機制恢復。

降低技術風險的方法包括充分的測試覆蓋,包括單元測試、整合測試、混沌工程測試。在測試環境模擬網路延遲、服務故障、資料庫不可用等場景,驗證系統的韌性。建立完善的可觀測性體系,快速發現與定位問題。培訓團隊掌握分散式系統設計模式,閱讀相關書籍與論文,從他人經驗中學習。

### 組織風險

微服務架構要求組織結構的配合,傳統的職能團隊如前端團隊、後端團隊、DBA 團隊難以支撐微服務的跨職能需求。理想的組織模式是特性團隊或產品團隊,每個團隊擁有端到端交付一個或多個服務的所有技能,包括開發、測試、運維、用戶體驗設計。

轉型到這種組織模式需要時間與文化變革。開發人員需要學習運維技能如容器化、監控、故障排查。運維人員需要更深入理解應用邏輯以提供有效支援。管理層需要調整考核指標,從個人產出轉向團隊成果,從專案完成度轉向業務價值交付。

### 成本風險

微服務架構的運營成本通常高於單體應用。需要更多的基礎設施如 Kubernetes 叢集、服務網格、監控系統。需要更多的人力投入運維工作,處理部署、升級、故障恢復。需要更多的通訊開銷,服務間的網路呼叫比進程內方法呼叫慢數個數量級。

控制成本的方法包括自動化一切可以自動化的工作,減少人工介入。使用託管服務如雲端 Kubernetes、託管資料庫降低運維負擔。持續優化資源使用,關閉閒置服務,使用 spot instance 降低運算成本。評估每個服務的價值,若某個服務的收益無法覆蓋其成本,考慮合併到其他服務或下線。

## 最佳實踐與經驗總結

### 逐步演進而非一次重寫

架構演進是馬拉松而非短跑,需要長期規劃與持續投入。不要試圖一次性重寫整個系統,那樣風險過高且很可能失敗。選擇最有價值的模組逐個拆分,每次拆分後穩定運行一段時間,團隊積累經驗,再拆分下一個模組。

每次演進都應該解決實際問題,為業務帶來可見價值。如果只是為了技術而技術,為了微服務而微服務,很難獲得組織支援且容易半途而廢。明確演進目標如提升某個功能的性能、加快某個團隊的交付速度、降低某個故障的影響範圍,用數據驗證演進效果。

### 保持架構簡單

架構應該隨業務複雜度自然演進,而不是超前設計。不要在使用者規模還很小時就建立支援百萬用戶的複雜架構,過早優化浪費資源且增加維護負擔。從簡單開始,當遇到瓶頸時再演進,這樣的架構成長過程最符合實際需求。

架構決策應該可逆,避免不可逆的重大決策鎖定未來選擇。使用抽象層與適配器模式,讓底層技術可以替換而不影響業務邏輯。例如資料庫存取透過 ORM 抽象,更換資料庫時只需要修改適配器。消息佇列透過統一介面,從 Redis 遷移到 RabbitMQ 不需要改動業務代碼。

### 文化與技能培養

技術架構的成功最終取決於人。團隊需要掌握微服務開發的技能如容器化、API 設計、分散式追蹤。團隊需要建立 DevOps 文化,開發對生產環境負責,主動監控系統健康,快速響應故障。團隊需要擁抱實驗與學習,不懼怕失敗,從錯誤中快速恢復。

投資於團隊成長,提供培訓機會,鼓勵參與開源社群,分享經驗教訓。建立導師制度,資深工程師指導初級成員,在實踐中傳承知識。定期舉行技術分享會,討論架構決策、故障分析、最佳實踐,讓整個團隊共同成長。

## 結語

Contracts-L1 的架構演進路徑是經過深思熟慮的漸進式設計,支援從初創階段到成熟企業的不同需求。關鍵是認識到沒有一種架構適合所有階段,根據當前的團隊規模、使用者規模、業務複雜度選擇最適合的架構,並為未來的演進做好準備。

從智能單體開始,專注產品價值驗證與快速迭代。當遇到明確的瓶頸時,演進到混合架構,拆分最有價值的服務。當組織與技術都成熟時,過渡到完全微服務,享受其帶來的靈活性與可擴展性。

整個過程中保持清醒的頭腦,每個架構決策都基於實際需求與數據,避免為了技術而技術的陷阱。架構是為業務服務的,好的架構應該讓業務目標更容易達成,而不是成為業務的負擔。

希望本指南能夠幫助您在 Contracts-L1 的演進旅程中做出明智的決策,建構出既滿足當前需求又具備未來擴展能力的優秀架構。
